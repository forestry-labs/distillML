Package: distillML
Type: Package
Title: Model Distillation and Interpretability Methods for Machine Learning Models
Version: 0.1.0.4
Authors@R: c(
    person("Brian", "Cho", role = "aut"),
    person("Theo", "Saarinen", role = c("aut","cre"), email = "theo_s@berkeley.edu"),
    person("Jasjeet", "Sekhon", role = "aut"),
    person("Simon", "Walter", role = "aut")
    )
Maintainer: Theo Saarinen <theo_s@berkeley.edu>
BugReports: https://github.com/forestry-labs/distillML/issues
URL: https://github.com/forestry-labs/distillML
Description: Provides several methods for model distillation and interpretability 
    for general black box machine learning models and treatment effect estimation
    methods.  Brian Cho, Theo F. Saarinen, Jasjeet S. Sekhon, Simon Walter.
License: GPL (>=3)
Encoding: UTF-8
Imports:
    ggplot2,
    glmnet,
    Rforestry,
    MASS,
    dplyr,
    R6 (>= 2.0),
    checkmate,
    purrr,
    tidyr,
    data.table,
    mltools,
    gridExtra
Suggests:
    testthat,
    knitr,
    rmarkdown,
    mvtnorm
Collate:
    'predictor.R'
    'interpret.R'
    'distiller.R'
    'plotter.R'
    'surrogate.R'
VignetteBuilder: knitr
RoxygenNote: 7.1.2
